{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wastewater_data(file_path):\n",
    "    \n",
    "    # Load wastewater data\n",
    "    wastewater_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Mapping dictionaries\n",
    "    country_mapping_ww = {\n",
    "        'AT': 'Austria',\n",
    "        'BE': 'Belgium',\n",
    "        'BG': 'Bulgaria',\n",
    "        'CH': 'Switzerland',\n",
    "        'CY': 'Cyprus',\n",
    "        'CZ': 'Czech Republic',\n",
    "        'DE': 'Germany',\n",
    "        'DK': 'Denmark',\n",
    "        'EE': 'Estonia',\n",
    "        'ES': 'Spain',\n",
    "        'FI': 'Finland',\n",
    "        'FR': 'France',\n",
    "        'GB': 'United Kingdom',\n",
    "        'GR': 'Greece',\n",
    "        'HR': 'Croatia',\n",
    "        'HU': 'Hungary',\n",
    "        'IE': 'Ireland',\n",
    "        'IS': 'Iceland',\n",
    "        'IT': 'Italy',\n",
    "        'LT': 'Lithuania',\n",
    "        'LU': 'Luxembourg',\n",
    "        'LV': 'Latvia',\n",
    "        'MT': 'Malta',\n",
    "        'NL': 'Netherlands',\n",
    "        'NO': 'Norway',\n",
    "        'PL': 'Poland',\n",
    "        'PT': 'Portugal',\n",
    "        'RO': 'Romania',\n",
    "        'RS': 'Serbia',\n",
    "        'SE': 'Sweden',\n",
    "        'SI': 'Slovenia',\n",
    "        'SK': 'Slovakia',\n",
    "        'TR': 'Turkey',\n",
    "        'UK': 'United Kingdom'\n",
    "    }\n",
    "\n",
    "    wastewater_drugs_mapping = {\n",
    "        'cocaine': 'Cocaine',\n",
    "        'cannabis': 'Cannabis'    \n",
    "    }\n",
    "\n",
    "    # Map the country abbreviations to full names in wastewater_data\n",
    "    wastewater_data['Country'] = wastewater_data['Country'].replace(country_mapping_ww)\n",
    "    wastewater_data['Metabolite'] = wastewater_data['Metabolite'].replace(wastewater_drugs_mapping)\n",
    "    wastewater_data = wastewater_data.drop(columns=['source'])\n",
    "    \n",
    "    # Ensure the column names are consistent\n",
    "    wastewater_data.rename(columns={'Country': 'country', 'Year': 'year', 'Metabolite': 'drug'}, inplace=True)\n",
    "    \n",
    "    # Filter the data\n",
    "    wastewater_data = wastewater_data[wastewater_data['year'] >= 2019]\n",
    "    wastewater_data = wastewater_data[wastewater_data['drug'].isin(['Cocaine', 'Cannabis', 'MDMA'])]\n",
    "    \n",
    "    return wastewater_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_forecasting_data():\n",
    "    country_mapping = {\n",
    "        'GERMANY': 'Germany',\n",
    "        'ITALY': 'Italy',\n",
    "        'POLAND': 'Poland',\n",
    "        'UK': 'United Kingdom',\n",
    "        'BELGIUM': 'Belgium',\n",
    "        'CZECHIA': 'Czech Republic',\n",
    "        'DANISH': 'Denmark',\n",
    "        'FRANCE': 'France',\n",
    "        'IRELAND': 'Ireland',\n",
    "        'LUXEMBOURG': 'Luxembourg',\n",
    "        'NETHERLANDS': 'Netherlands',\n",
    "        'PORTUGAL': 'Portugal',\n",
    "        'SPAIN': 'Spain',\n",
    "        'SWEDEN': 'Sweden',\n",
    "        'FRENCH': 'France',\n",
    "        'DENMARK': 'Denmark'\n",
    "    }\n",
    "\n",
    "    drugs_mapping = {\n",
    "        'COCAINE': 'Cocaine',\n",
    "        'marijuana': 'Cannabis'\n",
    "    }\n",
    "\n",
    "    def process_data(file, years):\n",
    "        data = pd.read_csv(file)\n",
    "        data['drug'] = data['drug'].replace(drugs_mapping)\n",
    "        data['country'] = data['country'].replace(country_mapping)\n",
    "        return data[(data['drug'].isin(['Cocaine', 'Cannabis', 'MDMA'])) & (data['year'].isin(years))][['year', 'country', 'drug', 'total']]\n",
    "\n",
    "    # Process and merge data\n",
    "    reddit_data = pd.concat([process_data('reddit_formatted.csv', [2020, 2021, 2022, 2023]), process_data('finish_for_david.csv', [2019])])\n",
    "\n",
    "    return reddit_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_combined_data(reddit_data, wastewater_data):\n",
    "    filtered_reddit_data = reddit_data[reddit_data['year'] == 2023]\n",
    "    filtered_reddit_data['litre/day per 1 000 inhabitants'] = np.nan\n",
    "\n",
    "    drug_list = wastewater_data['drug'].unique().tolist()\n",
    "\n",
    "    filtered_reddit_data = filtered_reddit_data[filtered_reddit_data['drug'].isin(drug_list)]\n",
    "\n",
    "    combined_data = pd.concat([filtered_reddit_data, combined_data])\n",
    "    combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "    counts = combined_data.groupby(['country', 'drug']).size()\n",
    "    max_count = counts.max()\n",
    "\n",
    "    filtered_counts = counts[counts == max_count]\n",
    "\n",
    "    combined_data = combined_data.set_index(['country', 'drug']).loc[filtered_counts.index].reset_index()\n",
    "    combined_data = combined_data.sort_values(by=['country', 'drug', 'year']).reset_index(drop=True)\n",
    "\n",
    "    combined_data.to_csv('combined_drug_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_drug_trends_data(file_path):\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter by specified countries\n",
    "    countries = ['Belgium', 'Czech Republic', 'Germany', 'Italy', 'Netherlands', 'Poland', 'Portugal', 'Spain', 'Sweden']\n",
    "    data = data[data['Country'].isin(countries)]\n",
    "\n",
    "    # Filter by specified substances\n",
    "    substances = ['Cannabis', 'Cocaine', 'Ecstasy']\n",
    "    data = data[data['Substance'].isin(substances)]\n",
    "\n",
    "    # Rename 'Ecstasy' to 'MDMA'\n",
    "    data['Substance'] = data['Substance'].replace('Ecstasy', 'MDMA')\n",
    "\n",
    "    # Rename 'Substance' column to 'drug'\n",
    "    data.rename(columns={'Substance': 'drug'}, inplace=True)\n",
    "\n",
    "    # Replace empty strings with NaN\n",
    "    data.replace('', np.nan, inplace=True)\n",
    "    data.replace(' ', np.nan, inplace=True)  # In case there are spaces\n",
    "\n",
    "    # Keep rows with 'Last year' and 'Adults (15-64)'\n",
    "    data = data[(data['Recall period'] == 'Last year') & (data['Age'] == 'Adults (15-64)')]\n",
    "\n",
    "    # Remove specified columns\n",
    "    columns_to_drop = ['Country code', 'Geographical scope', 'Recall period', 'Age']\n",
    "    data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_forecasting_data(file_path):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.drop(columns=['source'])\n",
    "\n",
    "    # Filter rows based on 'Country'\n",
    "    countries_to_keep = ['Belgium', 'Czech Republic', 'Germany', 'Italy', 'Netherlands', 'Poland', 'Portugal', 'Spain', 'Sweden']\n",
    "    data = data[data['Country'].isin(countries_to_keep)]\n",
    "\n",
    "    # Filter rows based on 'Substance'\n",
    "    substances_to_keep = ['cannabis', 'cocaine', 'MDMA']\n",
    "    data = data[data['Metabolite'].isin(substances_to_keep)]\n",
    "\n",
    "    # Rename 'Ecstasy' to 'MDMA' in 'Substance'\n",
    "    data['Metabolite'] = data['Metabolite'].replace('cannabis', 'Cannabis')\n",
    "    data['Metabolite'] = data['Metabolite'].replace('cocaine', 'Cocaine')\n",
    "\n",
    "    # Rename the column 'Substance' to 'drug'\n",
    "    data = data.rename(columns={'Metabolite': 'drug'})\n",
    "\n",
    "    data.to_csv('un_data_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_un_data(file_path, output_file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivoted_data = data.pivot_table(index=['Country', 'drug'], columns='Year', values='Percentage of the population', aggfunc='first').reset_index()\n",
    "\n",
    "    # Save the pivoted DataFrame back to a CSV file\n",
    "    pivoted_data.to_csv(output_file_path, index=False)\n",
    "file_path = 'un_data_cleaned.csv'  # Update this path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivoted_data = data.pivot_table(index=['Country', 'drug'], columns='Year', values='Percentage of the population', aggfunc='first').reset_index()\n",
    "\n",
    "# Save the pivoted DataFrame back to a CSV file if needed\n",
    "output_file_path = 'pivoted_un_data.csv'\n",
    "pivoted_data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def merge_and_clean_data(drug_trends_file, pivoted_un_data_file, output_file):\n",
    "    # Load the CSV files into DataFrames\n",
    "    drug_trends_df = pd.read_csv(drug_trends_file)\n",
    "    pivoted_un_data_df = pd.read_csv(pivoted_un_data_file)\n",
    "\n",
    "    # Merge the DataFrames on 'Country' and 'drug' columns using a left join\n",
    "    merged_df = pd.merge(drug_trends_df, pivoted_un_data_df, on=['Country', 'drug'], how='left', suffixes=('', '_enrich'))\n",
    "\n",
    "    # For each year with an \"_enrich\" column, update the main column if it's NaN and the \"_enrich\" column has a value.\n",
    "    for year in range(2004, 2022):  # Loop through the years that have enrichment data\n",
    "        year_col = str(year)\n",
    "        enrich_col = f\"{year_col}_enrich\"\n",
    "        # Where the main year column is NaN and the enrich column has a value, update the main column\n",
    "        merged_df[year_col] = merged_df.apply(lambda row: row[enrich_col] if pd.isna(row[year_col]) and not pd.isna(row[enrich_col]) else row[year_col], axis=1)\n",
    "\n",
    "    # Drop the \"_enrich\" columns after updating\n",
    "    columns_to_drop = [f\"{year}_enrich\" for year in range(2004, 2022)]\n",
    "    merged_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Save the merged and cleaned DataFrame to a CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def generate_synthetic_values(group, years_to_predict=[2019, 2020, 2021, 2022]):\n",
    "    numeric_values = group.select_dtypes(include=[np.number]).values.flatten()\n",
    "    years = np.arange(1990, 2023)  # Corresponding years\n",
    "    \n",
    "    available_data_mask = ~np.isnan(numeric_values)\n",
    "    available_years = years[available_data_mask]\n",
    "    available_values = numeric_values[available_data_mask]\n",
    "    \n",
    "    results = []\n",
    "    if len(available_years) >= 2:\n",
    "        X = available_years.reshape(-1, 1)\n",
    "        y = available_values\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        predictions = model.predict(np.array(years_to_predict).reshape(-1, 1))\n",
    "        for year, value in zip(years_to_predict, predictions):\n",
    "            results.append((year, value))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main_synthetic():\n",
    "    # Load your data\n",
    "    file_path = 'merged_un_emcdd.csv'  # Change this to your actual file path\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    synthetic_results = []\n",
    "    for (country, drug), group in data.groupby(['Country', 'drug']):\n",
    "        predictions = generate_synthetic_values(group)\n",
    "        for year, value in predictions:\n",
    "            synthetic_results.append({'Country': country, 'Drug': drug, 'Year': year, 'Value': value})\n",
    "\n",
    "    synthetic_data = pd.DataFrame(synthetic_results)\n",
    "    synthetic_data.to_csv('merged_synthetic_data.csv', index=False)  # Save to file\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_combined_drug_data(merged_synthetic_data_path, combined_drug_data_path, updated_combined_file_path):\n",
    "    merged_synthetic_data = pd.read_csv(merged_synthetic_data_path)\n",
    "    combined_drug_data = pd.read_csv(combined_drug_data_path)\n",
    "\n",
    "    # Rename the 'Value' column to 'percentage of users last year'\n",
    "    merged_synthetic_data.rename(columns={'Value': 'percentage of users last year'}, inplace=True)\n",
    "\n",
    "    # Correcting the merge operation to use lowercase column names to match the combined drug data\n",
    "    # Assume the combined drug data has columns named 'country', 'drug', 'year'\n",
    "    updated_combined_data = pd.merge(combined_drug_data, \n",
    "                                      merged_synthetic_data[['Country', 'Drug', 'Year', 'percentage of users last year']],\n",
    "                                      left_on=['country', 'drug', 'year'], \n",
    "                                      right_on=['Country', 'Drug', 'Year'], \n",
    "                                      how='left')\n",
    "\n",
    "    # Drop the duplicate columns from the merge operation, if necessary\n",
    "    updated_combined_data.drop(columns=['Country', 'Drug', 'Year'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Save the updated dataframe to a new CSV file\n",
    "    updated_combined_data.to_csv(updated_combined_file_path, index=False)\n",
    "\n",
    "    print(f\"Updated combined drug data saved to: {updated_combined_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurostat_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
